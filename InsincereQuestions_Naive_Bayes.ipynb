{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2b231c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "pd.set_option('display.max_columns', None)\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "import re # regular expression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e6d224e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f3cfed12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train  (1306122, 3)\n"
     ]
    }
   ],
   "source": [
    "print ('Shape of train ',data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "42d64e48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taking a look at Sincere Questions\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1071083</th>\n",
       "      <td>d1e0aac78b3c77ae57bf</td>\n",
       "      <td>Why do I feel lost, depressed and sad after qu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570365</th>\n",
       "      <td>6fc1a1d440e6fc0db3bd</td>\n",
       "      <td>What should you talk about on a first date wit...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402588</th>\n",
       "      <td>4ee3366051d1acf54aa1</td>\n",
       "      <td>Can you lose weight by eating nothing but rame...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337586</th>\n",
       "      <td>4224c3a11566b27fb678</td>\n",
       "      <td>What jobs for English speakers are needed in M...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1084214</th>\n",
       "      <td>d479c52b797ebd21de2b</td>\n",
       "      <td>Why do people get hysteria over global warming...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          qid  \\\n",
       "1071083  d1e0aac78b3c77ae57bf   \n",
       "570365   6fc1a1d440e6fc0db3bd   \n",
       "402588   4ee3366051d1acf54aa1   \n",
       "337586   4224c3a11566b27fb678   \n",
       "1084214  d479c52b797ebd21de2b   \n",
       "\n",
       "                                             question_text  target  \n",
       "1071083  Why do I feel lost, depressed and sad after qu...       0  \n",
       "570365   What should you talk about on a first date wit...       0  \n",
       "402588   Can you lose weight by eating nothing but rame...       0  \n",
       "337586   What jobs for English speakers are needed in M...       0  \n",
       "1084214  Why do people get hysteria over global warming...       0  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print ('Taking a look at Sincere Questions')\n",
    "data.loc[data['target'] == 0].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "fdf24311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taking a look at Insincere Questions\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "169888    Is it time for the US to ditch the EU and Cana...\n",
       "954514    Is it misogynistic to think that women will ne...\n",
       "15477     Why do men not Care about height? Do men just ...\n",
       "293918    Does the USA fit the definition of a bully? E....\n",
       "344000                  Is the US a jewocracy or democracy?\n",
       "Name: question_text, dtype: object"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print ('Taking a look at Insincere Questions')\n",
    "data.loc[data['target'] == 1].sample(5)['question_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "95376415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1306122 entries, 0 to 1306121\n",
      "Data columns (total 3 columns):\n",
      " #   Column         Non-Null Count    Dtype \n",
      "---  ------         --------------    ----- \n",
      " 0   qid            1306122 non-null  object\n",
      " 1   question_text  1306122 non-null  object\n",
      " 2   target         1306122 non-null  int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 29.9+ MB\n"
     ]
    }
   ],
   "source": [
    "#data = data[:5000]\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0748179",
   "metadata": {},
   "source": [
    "## Text Standardization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebb6583",
   "metadata": {},
   "source": [
    "### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "6be75f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(text):\n",
    "    filtered_stop_words = []\n",
    "    doc = nlp(text)\n",
    "    for token in doc:\n",
    "        if not token.is_stop and not token.is_punct: # we use token attribute .is_stop\n",
    "            filtered_stop_words.append(token.text)\n",
    "    return \" \".join(filtered_stop_words)\n",
    "def lemmatized_string(text):\n",
    "    doc = nlp(text)\n",
    "    lemmatized_string = []\n",
    "    for token in doc:\n",
    "        lemmatized_string.append(token.lemma_)\n",
    "    return \" \".join(lemmatized_string)\n",
    "\n",
    "def remove_URL(text):\n",
    "    url = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return url.sub(r'',text)\n",
    "\n",
    "def remove_html(text):\n",
    "    html=re.compile(r'<.*?>')\n",
    "    return html.sub(r'',text)\n",
    "\n",
    "def remove_emoji(text):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  \n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  \n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  \n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  \n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "07b9fcb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1306122 entries, 0 to 1306121\n",
      "Data columns (total 2 columns):\n",
      " #   Column         Non-Null Count    Dtype \n",
      "---  ------         --------------    ----- \n",
      " 0   question_text  1306122 non-null  object\n",
      " 1   target         1306122 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 19.9+ MB\n"
     ]
    }
   ],
   "source": [
    "data.drop(['qid'], axis=1, inplace=True)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85132d2",
   "metadata": {},
   "source": [
    "### Standardize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "8c6f3b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['question_text']= data['question_text'].apply(remove_stop_words)\n",
    "data['question_text']= data['question_text'].apply(lemmatized_string)\n",
    "data['question_text']= data['question_text'].apply(remove_URL)\n",
    "data['question_text']= data['question_text'].apply(remove_html)\n",
    "data['question_text']= data['question_text'].apply(remove_emoji)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "80dd31ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1177442</th>\n",
       "      <td>far 35 kilometer coast Hong Kong</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690449</th>\n",
       "      <td>physically emotionally abuse sociopath</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>925973</th>\n",
       "      <td>south Indians lack patriotism</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190107</th>\n",
       "      <td>Leia find fun work Jabba slave</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>930270</th>\n",
       "      <td>word man hate woman thing actually exist word ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             question_text  target\n",
       "1177442                   far 35 kilometer coast Hong Kong       0\n",
       "690449              physically emotionally abuse sociopath       0\n",
       "925973                       south Indians lack patriotism       1\n",
       "190107                      Leia find fun work Jabba slave       1\n",
       "930270   word man hate woman thing actually exist word ...       1"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e40e4a",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "571839e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(data, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f498f84f",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "0919a52c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "row_count = train.shape[0]\n",
    "\n",
    "total_word_count_dict = {}\n",
    "word_count_sincere = {}\n",
    "word_count_insincere = {}\n",
    "sincere  = 0\n",
    "insincere = 0 \n",
    "\n",
    "\n",
    "for row in range(0,row_count):\n",
    "    insincere += train.iloc[row]['target']\n",
    "    sincere += (1 - train.iloc[row]['target'])\n",
    "    sentence = train.iloc[row]['question_text']\n",
    "    words_in_sentence = list(set(sentence.split(' ')))\n",
    "    for word in words_in_sentence:\n",
    "        if train.iloc[row]['target'] == 0:   #Sincere Words\n",
    "            if word in word_count_sincere.keys():\n",
    "                word_count_sincere[word]+=1\n",
    "            else:\n",
    "                word_count_sincere[word] = 1\n",
    "        elif train.iloc[row]['target'] == 1: #Insincere Words\n",
    "            if word in word_count_insincere.keys():\n",
    "                word_count_insincere[word]+=1\n",
    "            else:\n",
    "                word_count_insincere[word] = 1\n",
    "        if word in total_word_count_dict.keys():        #For all words. I use this to compute probability.\n",
    "            total_word_count_dict[word]+=1\n",
    "        else:\n",
    "            total_word_count_dict[word]=1\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "9dc6360d",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_word_probability = {}\n",
    "total_words = 0\n",
    "for word in total_word_count_dict:\n",
    "    total_words += total_word_count_dict[word]\n",
    "for word in total_word_count_dict:\n",
    "    total_word_probability[word] = total_word_count_dict[word] / total_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e2d93232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words  210910\n",
      "Minimum probability  1.6672671607223869e-07\n",
      "Total words  1734\n"
     ]
    }
   ],
   "source": [
    "print ('Total words ',len(total_word_probability))\n",
    "print ('Minimum probability ',min (total_word_probability.values()))\n",
    "threshold_p = 0.0001\n",
    "for word in list(total_word_probability):\n",
    "    if total_word_probability[word] < threshold_p:\n",
    "        del total_word_probability[word]\n",
    "        if word in list(word_count_sincere):   #list(dict) return it;s key elements\n",
    "            del word_count_sincere[word]\n",
    "        if word in list(word_count_insincere):  \n",
    "            del word_count_insincere[word]\n",
    "print ('Total words ',len(total_word_probability))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "8db9fb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_sincere_words = sum(word_count_sincere.values())\n",
    "cp_sincere = {}  #Conditional Probability of the word given sentence is sincere\n",
    "for i in list(word_count_sincere):\n",
    "    cp_sincere[i] = word_count_sincere[i] / total_sincere_words\n",
    "\n",
    "total_insincere_words = sum(word_count_insincere.values())\n",
    "cp_insincere = {}  #Conditional Probability of the word given sentence is insincere\n",
    "for i in list(word_count_insincere):\n",
    "    cp_insincere[i] = word_count_insincere[i] / total_insincere_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ac0669a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "261225\n",
      "Accuracy is  94.25169872715092\n"
     ]
    }
   ],
   "source": [
    "row_count = test.shape[0]\n",
    "print(row_count)\n",
    "#p(y = \"insincere\" | X = [word1, word2, ..., wordn]) = p(word1 | y = \"insincere\").p(word2 | y = \"insincere\")...p(wordn | y = \"insincere\"). p(y=\"insincere\")\n",
    "#p(y = \"sincere\" | X = [word1, word2, ..., wordn]) = p(word1 | y = \"sincere\").p(word2 | y = \"sincere\")...p(wordn | y = \"sincere\"). p(y=\"sincere\")\n",
    "p_insincere = insincere / (sincere + insincere)\n",
    "p_sincere = sincere / (sincere + insincere)\n",
    "accuracy = 0\n",
    "\n",
    "for row in range(0,row_count):\n",
    "    sentence = test.iloc[row]['question_text']\n",
    "    target = test.iloc[row]['target']\n",
    "    words_in_sentence = list(set(sentence.split(' ')))\n",
    "    insincere_term = p_insincere\n",
    "    sincere_term = p_sincere\n",
    "    \n",
    "    sincere_M = len(cp_sincere.keys())\n",
    "    insincere_M = len(cp_insincere.keys())\n",
    "    for word in words_in_sentence:\n",
    "        if word not in cp_insincere.keys():\n",
    "            insincere_M +=1\n",
    "        if word not in cp_sincere.keys():\n",
    "            sincere_M += 1\n",
    "         \n",
    "    for word in words_in_sentence:\n",
    "        if word in cp_insincere.keys():\n",
    "            insincere_term *= (cp_insincere[word] + (1/insincere_M))\n",
    "        else:\n",
    "            insincere_term *= (1/insincere_M)\n",
    "        if word in cp_sincere.keys():\n",
    "            sincere_term *= (cp_sincere[word] + (1/sincere_M))\n",
    "        else:\n",
    "            sincere_term *= (1/sincere_M)\n",
    "        \n",
    "    if insincere_term/(insincere_term + sincere_term) > 0.5:\n",
    "        response = 1\n",
    "    else:\n",
    "        response = 0\n",
    "    if target == response:\n",
    "        accuracy += 1\n",
    "    \n",
    "print ('Accuracy is ',accuracy/row_count*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffa36c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
